{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NResumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import nltk\n",
    "from pyresparser import ResumeParser\n",
    "import pandas as pd\n",
    "import operator\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume_path = 'resume\\enqres'\n",
    "resume_path = 'resume' \n",
    "# resume_files = [os.path.join(resume_path, f) for f in os.listdir(resume_path) if os.path.isfile(os.path.join(resume_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_req = {'Data Science': {'Python':['scikitlearn','pandas','matplotlib'], 'Machine Learning':['Regression','ML','KNN'], 'Querying':['SQL','Hive','Pig'], 'Database':['SQL','MongoDB','Cassandra']},\n",
    "           \"Data Engineer\": {'Language':['Java','Scala','Python']},\n",
    "           \"Front-End\": {'Website':['HTML','CSS','JavaScript','JS'], 'Mobile':['React','React-Native','Flutter','Android','iOS']},\n",
    "           \"Back-End\": {'DBMS':['MySQL', 'MongoDB', 'Oracle', 'SQLServer', 'Redis'], 'Language':['Java', 'Python', 'Ruby', '.net']},\n",
    "           \"Software Engineer\": {'DBMS':['MySQL', 'MongoDB', 'Oracle', 'SQLServer', 'Redis'], 'Language':['Java', 'Python', 'Ruby', '.net']}\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in CSV data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Nresume\\\\csv\\\\cloud_architect.csv',\n",
       " 'C:\\\\Nresume\\\\csv\\\\data_scientist.csv',\n",
       " 'C:\\\\Nresume\\\\csv\\\\full_stack_dev.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data = {} # a dictionary to store all the dataframes\n",
    "profile_path = \"C:\\\\Nresume\\\\csv\"\n",
    "\n",
    "#get a list consisting of the paths of all the csv files \n",
    "profile_files = [os.path.join(profile_path, f) for f in os.listdir(profile_path) if os.path.isfile(os.path.join(profile_path, f))]\n",
    "\n",
    "for file in profile_files:\n",
    "    keyname = os.path.basename(file)[:-len('.csv')]  #this is just to obtain every file name sans the extension  \n",
    "    #print(keyname)\n",
    "    x = pd.read_csv(file)\n",
    "    profile_data[keyname] = x.apply(lambda x:x.astype(str).str.lower()) \n",
    "\n",
    "profiles_list = list(profile_data.keys()) #Just storing the profile in list format\n",
    " \n",
    "profile_files    \n",
    "#profile_data['data_scientist']# printing a sample one for data scientist\n",
    "#profile_data['full_stack_dev']# printing a sample one for data scientist\n",
    "#profile_data['cloud_architect']# printing a sample one for data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying resumes on job description and storing them in their respective folders\n",
    "We have a dataframe that has the skills for each job, we shall iterate through the folder containing all resumes, for each resume calculate the skills (add +1 for each mention of the skill) and store it in the job folder that has the max score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### resume_files = [os.path.join(resume_path, f) for f in os.listdir(resume_path) if os.path.isfile(os.path.join(resume_path, f))]\n",
    "\n",
    "#for each file in resume_path, reading the resumes and extracting info\n",
    "\n",
    "for f in os.listdir(resume_path):\n",
    "\n",
    "    if os.path.isfile(os.path.join(resume_path, f)):\n",
    "        \n",
    "        data = ResumeParser(os.path.join(resume_path, f)).get_extracted_data()\n",
    "        print(data)\n",
    "        print(\" \")\n",
    "    \n",
    "        proficiency = []\n",
    "        \n",
    "        #Iterating through all the job dataframes in profile_data and \n",
    "        #For each job, iterate through all skills \n",
    "        #If skills match skills from resume increment specific_skills by one\n",
    "        \n",
    "        data_series = pd.Series([i.lower() for i in data['skills']]) #convert all the skills to lowercase\n",
    "        \n",
    "        #print(data_series)\n",
    "        #print(\"   \")\n",
    "        \n",
    "        for jobs,jobs_df in profile_data.items():\n",
    "            #print(jobs)\n",
    "            talent_in_job=0  #a metric to measure skill in a job profile based on number of mentions in resume\n",
    "            \n",
    "            for skills_col in jobs_df.columns:\n",
    "                #print(jobs_df[skills_col])\n",
    "                #skills_col_lower=jobs_df[skills_col].str.lower()\n",
    "                #print(len(list(set(data_series).intersection(set(skills_col_lower)))))\n",
    "                \n",
    "                talent_in_job+=len(list(set(data_series).intersection(set(jobs_df[skills_col]))))\n",
    "            \n",
    "            proficiency.append(talent_in_job)\n",
    "            #proficiency_measure[jobs] = talent_in_job                \n",
    "        \n",
    "        #get the name of the job that has most matches and move the file to the job's folder\n",
    "        \n",
    "        #x = max(proficiency_measure.items(), key=operator.itemgetter(1))[0]\n",
    "        #x = x.lower()\n",
    "        \n",
    "        most_proficient = proficiency.index(max(proficiency))\n",
    "        new_directory = os.path.join(resume_path,profiles_list[most_proficient],f)\n",
    "        old_directory = os.path.join(resume_path, f)\n",
    "        shutil.move(old_directory,new_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Input for skills, experience and how many resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Requirements or q to exitq\n",
      "How many resumes would you like identified?  4\n"
     ]
    }
   ],
   "source": [
    "user_requirements = []\n",
    "requirement = None\n",
    "while requirement != 'q':\n",
    "    requirement = input(\"Enter Requirements or q to exit \")\n",
    "    user_requirements.append(requirement)\n",
    "    \n",
    "num_resumes = input(\"How many resumes would you like identified?  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
