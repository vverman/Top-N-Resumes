{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NResumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import nltk\n",
    "from pyresparser import ResumeParser\n",
    "import pandas as pd\n",
    "import operator\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume_path = 'resume\\enqres'\n",
    "resume_path = 'resume' \n",
    "# resume_files = [os.path.join(resume_path, f) for f in os.listdir(resume_path) if os.path.isfile(os.path.join(resume_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_req = {'Data Science': {'Python':['scikitlearn','pandas','matplotlib'], 'Machine Learning':['Regression','ML','KNN'], 'Querying':['SQL','Hive','Pig'], 'Database':['SQL','MongoDB','Cassandra']},\n",
    "           \"Data Engineer\": {'Language':['Java','Scala','Python']},\n",
    "           \"Front-End\": {'Website':['HTML','CSS','JavaScript','JS'], 'Mobile':['React','React-Native','Flutter','Android','iOS']},\n",
    "           \"Back-End\": {'DBMS':['MySQL', 'MongoDB', 'Oracle', 'SQLServer', 'Redis'], 'Language':['Java', 'Python', 'Ruby', '.net']},\n",
    "           \"Software Engineer\": {'DBMS':['MySQL', 'MongoDB', 'Oracle', 'SQLServer', 'Redis'], 'Language':['Java', 'Python', 'Ruby', '.net']}\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in CSV data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Nresume\\\\csv\\\\cloud_architect.csv',\n",
       " 'C:\\\\Nresume\\\\csv\\\\data_scientist.csv',\n",
       " 'C:\\\\Nresume\\\\csv\\\\full_stack_dev.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data = {} # a dictionary to store all the dataframes\n",
    "profile_path = \"C:\\\\Nresume\\\\csv\"\n",
    "\n",
    "#get a list consisting of the paths of all the csv files \n",
    "profile_files = [os.path.join(profile_path, f) for f in os.listdir(profile_path) if os.path.isfile(os.path.join(profile_path, f))]\n",
    "\n",
    "for file in profile_files:\n",
    "    keyname = os.path.basename(file)[:-len('.csv')]  #this is just to obtain every file name sans the extension  \n",
    "    #print(keyname)\n",
    "    x = pd.read_csv(file)\n",
    "    profile_data[keyname] = x.apply(lambda x:x.astype(str).str.lower()) \n",
    "\n",
    "profiles_list = list(profile_data.keys()) #Just storing the profile in list format\n",
    " \n",
    "profile_files    \n",
    "#profile_data['data_scientist']# printing a sample one for data scientist\n",
    "#profile_data['full_stack_dev']# printing a sample one for data scientist\n",
    "#profile_data['cloud_architect']# printing a sample one for data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying resumes on job description and storing them in their respective folders\n",
    "We have a dataframe that has the skills for each job, we shall iterate through the folder containing all resumes, for each resume calculate the skills (add +1 for each mention of the skill) and store it in the job folder that has the max score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Communication Engineering', 'email': 's.sarvani1998@gmail.com', 'mobile_number': '9176473886', 'skills': ['Finance', 'C', 'Budget', 'Electronics', 'Scripting', 'Robot', 'Engineering', 'Statistics', 'Python', 'Modeling', 'Excel', 'Matlab', 'Email', 'Communication', 'Analytical', 'Machine learning', 'C++', 'Spanish', 'Facebook', 'System', 'Javascript', 'Engagement', 'Social media', 'Data analytics', 'Content', 'R', 'Cloud', 'International', 'Microsoft excel', 'Java', 'Acquisition', 'Twitter', 'Analytics', 'Mobile'], 'college_name': None, 'degree': ['Bachelor of Technology, ECE (2016 -2020)', 'Degree anticipated in May 2020'], 'designation': None, 'experience': ['Data Acquisition Intern                                 ISRO SDSC SHAR, June 2019', '\\uf0a7  Analyzed  and  compiled  data  gathered  from  various  sensors  for  different  parameters', '(temperature, pressure, humidity, acoustic levels)', '\\uf0a7  Worked with PIC microcontroller and software like Origin and LABView', '\\uf0a7  Real time data from static motors was acquired and tested for results.', 'IOT Intern                                                      Signals & Systems, June 2018- July 2018', '\\uf0a7  Worked on Python and Embedded C scripting'], 'company_names': None, 'no_of_pages': 2, 'total_experience': 0.08}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "##### resume_files = [os.path.join(resume_path, f) for f in os.listdir(resume_path) if os.path.isfile(os.path.join(resume_path, f))]\n",
    "\n",
    "#for each file in resume_path, reading the resumes and extracting info\n",
    "\n",
    "for f in os.listdir(resume_path):\n",
    "\n",
    "    if os.path.isfile(os.path.join(resume_path, f)):\n",
    "        \n",
    "        data = ResumeParser(os.path.join(resume_path, f)).get_extracted_data()\n",
    "        print(data)\n",
    "        print(\" \")\n",
    "    \n",
    "        proficiency = []\n",
    "        \n",
    "        #Iterating through all the job dataframes in profile_data and \n",
    "        #For each job, iterate through all skills \n",
    "        #If skills match skills from resume increment specific_skills by one\n",
    "        \n",
    "        data_series = pd.Series([i.lower() for i in data['skills']]) #convert all the skills to lowercase\n",
    "        \n",
    "        #print(data_series)\n",
    "        #print(\"   \")\n",
    "        \n",
    "        for jobs,jobs_df in profile_data.items():\n",
    "            #print(jobs)\n",
    "            talent_in_job=0  #a metric to measure skill in a job profile based on number of mentions in resume\n",
    "            \n",
    "            for skills_col in jobs_df.columns:\n",
    "                #print(jobs_df[skills_col])\n",
    "                #skills_col_lower=jobs_df[skills_col].str.lower()\n",
    "                #print(len(list(set(data_series).intersection(set(skills_col_lower)))))\n",
    "                \n",
    "                talent_in_job+=len(list(set(data_series).intersection(set(jobs_df[skills_col]))))\n",
    "            \n",
    "            proficiency.append(talent_in_job)\n",
    "            #proficiency_measure[jobs] = talent_in_job                \n",
    "        \n",
    "        #get the name of the job that has most matches and move the file to the job's folder\n",
    "        \n",
    "        #x = max(proficiency_measure.items(), key=operator.itemgetter(1))[0]\n",
    "        #x = x.lower()\n",
    "        \n",
    "        most_proficient = proficiency.index(max(proficiency))\n",
    "        new_directory = os.path.join(resume_path,profiles_list[most_proficient],f)\n",
    "        old_directory = os.path.join(resume_path, f)\n",
    "        shutil.move(old_directory,new_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Input for skills, experience and how many resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Requirements or q to exitq\n",
      "How many resumes would you like identified?  4\n"
     ]
    }
   ],
   "source": [
    "user_requirements = []\n",
    "requirement = None\n",
    "while requirement != 'q':\n",
    "    requirement = input(\"Enter Requirements or q to exit \")\n",
    "    user_requirements.append(requirement)\n",
    "    \n",
    "num_resumes = input(\"How many resumes would you like identified?  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omkar Pathak\n",
      "12\n",
      "SOFTWARE ENGINEER · FULL STACK PYTHON DEVELOPER\n",
      "47\n",
      "Pune, Maharashtra, India\n",
      "24\n",
      " (+91) 8087996634 |  omkarpathak27@gmail.com |  www.omkarpathak.in |  OmkarPathak |  omkar-pathak-94473811b\n",
      "112\n",
      "“Make the change that you want to see in the world.”\n",
      "52\n",
      "Experience\n",
      "10\n",
      "Schlumberger Pune, Maharashtra, India\n",
      "37\n",
      "DATA ENGINEER July 2018 - Present\n",
      "33\n",
      "• Responsible for implementing and managing an end-to-end CI/CD Pipeline with custom validations for Informatica migrations which\n",
      "129\n",
      "brought migration time to 1.5 hours from 9 hours without any manual intervention\n",
      "80\n",
      "• Enhancing, auditing and maintaining custom data ingestion framework that ingest around 1TB of data each day to over 70 business\n",
      "129\n",
      "units\n",
      "5\n",
      "• Working with L3 developer team to ensure the discussed Scrum PBI’s are delivered on time for data ingestions\n",
      "110\n",
      "• Planning and Executing QA and Production Release Cycle activities\n",
      "67\n",
      "Truso Pune, Maharashtra, India\n",
      "30\n",
      "FULL STACK DEVELOPER INTERN June 2018 - July 2018\n",
      "49\n",
      "• Created RESTful apis\n",
      "22\n",
      "• Tried my hands on Angular 5/6\n",
      "31\n",
      "• Was responsible for Django backend development\n",
      "48\n",
      "Propeluss Pune, Maharashtra, India\n",
      "34\n",
      "DATA ENGINEERING INTERN October 2017 - January 2018\n",
      "51\n",
      "• Wrote various automation scripts to scrape data from various websites.\n",
      "72\n",
      "• Applied Natural Language Processing to articles scraped from the internet to extract different entities in these articles using entity\n",
      "136\n",
      "extraction algorithms and applying Machine Learning to classify these articles.\n",
      "79\n",
      "• Also applied KNN with LSA for extracting relevant tags for various startups based on their works.\n",
      "99\n",
      "GeeksForGeeks Pune, Maharashtra, India\n",
      "38\n",
      "TECHNICAL CONTENT WRITER July 2017 - September 2017\n",
      "51\n",
      "• Published 4 articles for the topics such as Data Structures and Algorithms and Python\n",
      "87\n",
      "Softtestlab Technologies Pune, Maharashtra, India\n",
      "49\n",
      "WEB DEVELOPER INTERN June 2017 - July 2017\n",
      "42\n",
      "• Was responsible for creating an internal project for the company using PHP and Laravel for testing purposes\n",
      "109\n",
      "• Worked on a live project for creating closure reports using PHP and Excel\n",
      "75\n",
      "Projects\n",
      "8\n",
      "Pyresparser API/Python Package\n",
      "30\n",
      "PERSONAL PROJECT July 2019 - Present\n",
      "36\n",
      "• A simple resume parser used for extracting information from resumes\n",
      "69\n",
      "• Extract information from thousands of resumes in just a few seconds\n",
      "69\n",
      "• Author and maintainer of this project\n",
      "39\n",
      "Garbage Level Monitoring System IoT\n",
      "35\n",
      "TEAM PROJECT October 2017 - May 2018\n",
      "36\n",
      "• To find a economical and smarter alternative to current garbage problems\n",
      "74\n",
      "• Users can monitor levels of all garbage bins from a global dashboard provided\n",
      "79\n",
      "• Was responsible for Django backend development\n",
      "48\n",
      "NOVEMBER 3, 2019 OMKAR PATHAK · RÉSUMÉ 1\n",
      "40\n",
      "Pygorithm API / Python Package\n",
      "30\n",
      "PERSONAL PROJECT July 2017 - Present\n",
      "36\n",
      "• Author and maintainer of this project\n",
      "39\n",
      "• An educational library to teach all the major algorithms\n",
      "58\n",
      "• Got covered in Fosstack, FullStackFeed, Kleiber and Tagged under Hotest Github Project on ITCodeMonkey\n",
      "104\n",
      "Smart Surveillance System using Raspberry Pi and Face Recognition IoT\n",
      "69\n",
      "PERSONAL PROJECT January 2017 - February 2017\n",
      "45\n",
      "• Face Recognition using OpenCV and Python\n",
      "42\n",
      "• Raspberry Pi was used as the data server\n",
      "42\n",
      "• User notified if any suspicious activity detected in real time\n",
      "64\n",
      "Password Strength Evaluator using Machine Learning Machine Learning\n",
      "67\n",
      "PERSONAL PROJECT March 2017\n",
      "27\n",
      "• SVM algorithm used for training and classification\n",
      "52\n",
      "• Flask framework used\n",
      "22\n",
      "• Self-generated dataset\n",
      "24\n",
      "Education\n",
      "9\n",
      "Marathwada Mitra Mandal’s College of Engineering Pune, Maharashtra, India\n",
      "73\n",
      "B.E. IN COMPUTER ENGINEERING 2014 - 2018\n",
      "40\n",
      "• Aggregate 74%\n",
      "15\n",
      "Skills\n",
      "6\n",
      "Programming Languages: Python, C, PHP, C++, Shell Script\n",
      "56\n",
      "Frontend Technologies: HTML, CSS, JavaScript, Angular 6/7\n",
      "57\n",
      "Backend Technologies: Django, Flask (Python), Laravel (PHP)\n",
      "59\n",
      "Operating Systems: Linux, Unix, Windows\n",
      "39\n",
      "Databases: MySQL, SQLite, MongoDB\n",
      "33\n",
      "Other: Git, NLP, Scikit-Learn, OpenCV, Cloud (GCP, Azure, DigitalOcean)\n",
      "71\n",
      "Honors & Awards\n",
      "15\n",
      "2018 Top rated Python developer, in Pune and Fifth in India at Github India\n",
      "75\n",
      "2018 Quora Top Writer, India\n",
      "28\n",
      "2018 Awarded ‘The Best Outgoing Student Award 2017-18’, MMCOE, Pune\n",
      "67\n",
      "2018 Won 2nd Prize, in an Hackathon organized by MIT-ADT Persona Fest 2018 Pune\n",
      "79\n",
      "2018\n",
      "4\n",
      "Best Paper Award, in National Level Conference on “Emerging Trends in Computing , Analytics\n",
      "91\n",
      "and Security - 2018”(NCETCAS-2018)\n",
      "34\n",
      "MMCOE, Pune\n",
      "11\n",
      "Extracurricular Activities\n",
      "26\n",
      "Contributor in Pune PyCon 2018\n",
      "30\n",
      "PUNE, MAHARASHTRA, INDIA 2018\n",
      "29\n",
      "• Was a part of Website Designing and volunteering committee\n",
      "60\n",
      "NOVEMBER 3, 2019 OMKAR PATHAK · RÉSUMÉ 2\n",
      "40\n",
      "Mentor at GirlScript Summer of Code 2019\n",
      "40\n",
      "PUNE, MAHARASHTRA, INDIA 2019\n",
      "29\n",
      "• Mentored 4+ teams in various domains\n",
      "38\n",
      "Organizing head for the National level technical event -\n",
      "56\n",
      "Innovatus\n",
      "9\n",
      "PUNE, MAHARASHTRA, INDIA 2018\n",
      "29\n",
      "• Organized project competitions\n",
      "32\n",
      "Workshop on IoT and Python\n",
      "26\n",
      "MMCOE, PUNE 10 Jan 2017\n",
      "23\n",
      "• Conducted a workshop for second year students to give them a brief overview about IoT by completing three mini projects and taught\n",
      "132\n",
      "them basics of Python programming language\n",
      "42\n",
      "Publications\n",
      "12\n",
      "Smart Surveillance System using Raspberry Pi and Face\n",
      "53\n",
      "Recognition DOI10.17148/IJARCCE.2017.64117\n",
      "42\n",
      "Garbage Level Monitoring System\n",
      "31\n",
      "Interests\n",
      "9\n",
      "• Competitive Programming\n",
      "25\n",
      "• Photography\n",
      "13\n",
      "• Sketching\n",
      "11\n",
      "• Reading/Writing on Quora\n",
      "26\n",
      "• Contributing to Open Source projects\n",
      "38\n",
      "NOVEMBER 3, 2019 OMKAR PATHAK · RÉSUMÉ 3\n",
      "40\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "text = ''' Omkar Pathak\n",
    "SOFTWARE ENGINEER · FULL STACK PYTHON DEVELOPER\n",
    "Pune, Maharashtra, India\n",
    " (+91) 8087996634 |  omkarpathak27@gmail.com |  www.omkarpathak.in |  OmkarPathak |  omkar-pathak-94473811b\n",
    "“Make the change that you want to see in the world.”\n",
    "Experience\n",
    "Schlumberger Pune, Maharashtra, India\n",
    "DATA ENGINEER July 2018 - Present\n",
    "• Responsible for implementing and managing an end-to-end CI/CD Pipeline with custom validations for Informatica migrations which\n",
    "brought migration time to 1.5 hours from 9 hours without any manual intervention\n",
    "• Enhancing, auditing and maintaining custom data ingestion framework that ingest around 1TB of data each day to over 70 business\n",
    "units\n",
    "• Working with L3 developer team to ensure the discussed Scrum PBI’s are delivered on time for data ingestions\n",
    "• Planning and Executing QA and Production Release Cycle activities\n",
    "Truso Pune, Maharashtra, India\n",
    "FULL STACK DEVELOPER INTERN June 2018 - July 2018\n",
    "• Created RESTful apis\n",
    "• Tried my hands on Angular 5/6\n",
    "• Was responsible for Django backend development\n",
    "Propeluss Pune, Maharashtra, India\n",
    "DATA ENGINEERING INTERN October 2017 - January 2018\n",
    "• Wrote various automation scripts to scrape data from various websites.\n",
    "• Applied Natural Language Processing to articles scraped from the internet to extract different entities in these articles using entity\n",
    "extraction algorithms and applying Machine Learning to classify these articles.\n",
    "• Also applied KNN with LSA for extracting relevant tags for various startups based on their works.\n",
    "GeeksForGeeks Pune, Maharashtra, India\n",
    "TECHNICAL CONTENT WRITER July 2017 - September 2017\n",
    "• Published 4 articles for the topics such as Data Structures and Algorithms and Python\n",
    "Softtestlab Technologies Pune, Maharashtra, India\n",
    "WEB DEVELOPER INTERN June 2017 - July 2017\n",
    "• Was responsible for creating an internal project for the company using PHP and Laravel for testing purposes\n",
    "• Worked on a live project for creating closure reports using PHP and Excel\n",
    "Projects\n",
    "Pyresparser API/Python Package\n",
    "PERSONAL PROJECT July 2019 - Present\n",
    "• A simple resume parser used for extracting information from resumes\n",
    "• Extract information from thousands of resumes in just a few seconds\n",
    "• Author and maintainer of this project\n",
    "Garbage Level Monitoring System IoT\n",
    "TEAM PROJECT October 2017 - May 2018\n",
    "• To find a economical and smarter alternative to current garbage problems\n",
    "• Users can monitor levels of all garbage bins from a global dashboard provided\n",
    "• Was responsible for Django backend development\n",
    "NOVEMBER 3, 2019 OMKAR PATHAK · RÉSUMÉ 1\n",
    "Pygorithm API / Python Package\n",
    "PERSONAL PROJECT July 2017 - Present\n",
    "• Author and maintainer of this project\n",
    "• An educational library to teach all the major algorithms\n",
    "• Got covered in Fosstack, FullStackFeed, Kleiber and Tagged under Hotest Github Project on ITCodeMonkey\n",
    "Smart Surveillance System using Raspberry Pi and Face Recognition IoT\n",
    "PERSONAL PROJECT January 2017 - February 2017\n",
    "• Face Recognition using OpenCV and Python\n",
    "• Raspberry Pi was used as the data server\n",
    "• User notified if any suspicious activity detected in real time\n",
    "Password Strength Evaluator using Machine Learning Machine Learning\n",
    "PERSONAL PROJECT March 2017\n",
    "• SVM algorithm used for training and classification\n",
    "• Flask framework used\n",
    "• Self-generated dataset\n",
    "Education\n",
    "Marathwada Mitra Mandal’s College of Engineering Pune, Maharashtra, India\n",
    "B.E. IN COMPUTER ENGINEERING 2014 - 2018\n",
    "• Aggregate 74%\n",
    "Skills\n",
    "Programming Languages: Python, C, PHP, C++, Shell Script\n",
    "Frontend Technologies: HTML, CSS, JavaScript, Angular 6/7\n",
    "Backend Technologies: Django, Flask (Python), Laravel (PHP)\n",
    "Operating Systems: Linux, Unix, Windows\n",
    "Databases: MySQL, SQLite, MongoDB\n",
    "Other: Git, NLP, Scikit-Learn, OpenCV, Cloud (GCP, Azure, DigitalOcean)\n",
    "Honors & Awards\n",
    "2018 Top rated Python developer, in Pune and Fifth in India at Github India\n",
    "2018 Quora Top Writer, India\n",
    "2018 Awarded ‘The Best Outgoing Student Award 2017-18’, MMCOE, Pune\n",
    "2018 Won 2nd Prize, in an Hackathon organized by MIT-ADT Persona Fest 2018 Pune\n",
    "2018\n",
    "Best Paper Award, in National Level Conference on “Emerging Trends in Computing , Analytics\n",
    "and Security - 2018”(NCETCAS-2018)\n",
    "MMCOE, Pune\n",
    "Extracurricular Activities\n",
    "Contributor in Pune PyCon 2018\n",
    "PUNE, MAHARASHTRA, INDIA 2018\n",
    "• Was a part of Website Designing and volunteering committee\n",
    "NOVEMBER 3, 2019 OMKAR PATHAK · RÉSUMÉ 2\n",
    "Mentor at GirlScript Summer of Code 2019\n",
    "PUNE, MAHARASHTRA, INDIA 2019\n",
    "• Mentored 4+ teams in various domains\n",
    "Organizing head for the National level technical event -\n",
    "Innovatus\n",
    "PUNE, MAHARASHTRA, INDIA 2018\n",
    "• Organized project competitions\n",
    "Workshop on IoT and Python\n",
    "MMCOE, PUNE 10 Jan 2017\n",
    "• Conducted a workshop for second year students to give them a brief overview about IoT by completing three mini projects and taught\n",
    "them basics of Python programming language\n",
    "Publications\n",
    "Smart Surveillance System using Raspberry Pi and Face\n",
    "Recognition DOI10.17148/IJARCCE.2017.64117\n",
    "Garbage Level Monitoring System\n",
    "Interests\n",
    "• Competitive Programming\n",
    "• Photography\n",
    "• Sketching\n",
    "• Reading/Writing on Quora\n",
    "• Contributing to Open Source projects\n",
    "NOVEMBER 3, 2019 OMKAR PATHAK · RÉSUMÉ 3\n",
    "'''\n",
    "\n",
    "text_split = [i.strip() for i in text.split('\\n')]\n",
    "\n",
    "for phrase in text_split:\n",
    "    print(phrase)\n",
    "    print(len(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = set([1,2,3,4])\n",
    "y = set([2,7,8,9])\n",
    "z = x&y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
